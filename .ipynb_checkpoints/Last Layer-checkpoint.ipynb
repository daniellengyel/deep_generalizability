{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle,os, copy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "from deep_generalizability.nets import Nets\n",
    "from deep_generalizability.utils import *\n",
    "from deep_generalizability.postprocessing.postprocessing import *\n",
    "from deep_generalizability.postprocessing.stats_plotting import *\n",
    "from deep_generalizability.save_load import *\n",
    "\n",
    "from deep_generalizability.postprocessing.sharpness_measures import *\n",
    "from deep_generalizability.postprocessing.stats_plotting import *\n",
    "\n",
    "from deep_generalizability.data_getters import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (13,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = os.environ[\"PATH_TO_DEEP_FOLDER\"]\n",
    "data_name = \"concentric_balls\"\n",
    "exp = \"Sep01_17-35-24_Daniels-MacBook-Pro-4.local\"\n",
    "experiment_folder = os.path.join(root_folder, \"experiments\", data_name, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = get_end_stats(experiment_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc Gap Mean</th>\n",
       "      <th>Acc Test Max</th>\n",
       "      <th>Acc Test Mean</th>\n",
       "      <th>Acc Test Min</th>\n",
       "      <th>Acc Train Max</th>\n",
       "      <th>Acc Train Mean</th>\n",
       "      <th>Acc Train Min</th>\n",
       "      <th>Loss Test Max</th>\n",
       "      <th>Loss Test Mean</th>\n",
       "      <th>Loss Test Min</th>\n",
       "      <th>Loss Train Max</th>\n",
       "      <th>Loss Train Mean</th>\n",
       "      <th>Loss Train Min</th>\n",
       "      <th>Norm Max</th>\n",
       "      <th>Norm Mean</th>\n",
       "      <th>Norm Min</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598974549.467531</th>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.254933</td>\n",
       "      <td>0.254933</td>\n",
       "      <td>0.254933</td>\n",
       "      <td>0.246102</td>\n",
       "      <td>0.246102</td>\n",
       "      <td>0.246102</td>\n",
       "      <td>10.941703</td>\n",
       "      <td>10.941703</td>\n",
       "      <td>10.941703</td>\n",
       "      <td>0.599484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598974548.179845</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.292642</td>\n",
       "      <td>0.292642</td>\n",
       "      <td>0.292642</td>\n",
       "      <td>0.271134</td>\n",
       "      <td>0.271134</td>\n",
       "      <td>0.271134</td>\n",
       "      <td>7.752036</td>\n",
       "      <td>7.752036</td>\n",
       "      <td>7.752036</td>\n",
       "      <td>0.359381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598974547.04371</th>\n",
       "      <td>0.075</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.490035</td>\n",
       "      <td>0.490035</td>\n",
       "      <td>0.490035</td>\n",
       "      <td>0.547508</td>\n",
       "      <td>0.547508</td>\n",
       "      <td>0.547508</td>\n",
       "      <td>4.784381</td>\n",
       "      <td>4.784381</td>\n",
       "      <td>4.784381</td>\n",
       "      <td>0.215443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598974545.712321</th>\n",
       "      <td>0.070</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.549718</td>\n",
       "      <td>0.549718</td>\n",
       "      <td>0.549718</td>\n",
       "      <td>4.340151</td>\n",
       "      <td>4.340151</td>\n",
       "      <td>4.340151</td>\n",
       "      <td>0.129155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598974542.469734</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.500382</td>\n",
       "      <td>0.500382</td>\n",
       "      <td>0.500382</td>\n",
       "      <td>0.554991</td>\n",
       "      <td>0.554991</td>\n",
       "      <td>0.554991</td>\n",
       "      <td>2.882570</td>\n",
       "      <td>2.882570</td>\n",
       "      <td>2.882570</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598974545.1420789</th>\n",
       "      <td>0.066</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.493422</td>\n",
       "      <td>0.493422</td>\n",
       "      <td>0.493422</td>\n",
       "      <td>0.549122</td>\n",
       "      <td>0.549122</td>\n",
       "      <td>0.549122</td>\n",
       "      <td>4.016640</td>\n",
       "      <td>4.016640</td>\n",
       "      <td>4.016640</td>\n",
       "      <td>0.0774264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598974544.1796732</th>\n",
       "      <td>0.059</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.494121</td>\n",
       "      <td>0.494121</td>\n",
       "      <td>0.494121</td>\n",
       "      <td>0.549191</td>\n",
       "      <td>0.549191</td>\n",
       "      <td>0.549191</td>\n",
       "      <td>3.737629</td>\n",
       "      <td>3.737629</td>\n",
       "      <td>3.737629</td>\n",
       "      <td>0.0464159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598974542.7061949</th>\n",
       "      <td>0.059</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.498270</td>\n",
       "      <td>0.498270</td>\n",
       "      <td>0.498270</td>\n",
       "      <td>0.551775</td>\n",
       "      <td>0.551775</td>\n",
       "      <td>0.551775</td>\n",
       "      <td>3.169239</td>\n",
       "      <td>3.169239</td>\n",
       "      <td>3.169239</td>\n",
       "      <td>0.016681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598974543.313955</th>\n",
       "      <td>0.059</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.495550</td>\n",
       "      <td>0.495550</td>\n",
       "      <td>0.495550</td>\n",
       "      <td>0.549952</td>\n",
       "      <td>0.549952</td>\n",
       "      <td>0.549952</td>\n",
       "      <td>3.462085</td>\n",
       "      <td>3.462085</td>\n",
       "      <td>3.462085</td>\n",
       "      <td>0.0278256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598974550.4215832</th>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.575710</td>\n",
       "      <td>0.575710</td>\n",
       "      <td>0.575710</td>\n",
       "      <td>0.522428</td>\n",
       "      <td>0.522428</td>\n",
       "      <td>0.522428</td>\n",
       "      <td>14.035298</td>\n",
       "      <td>14.035298</td>\n",
       "      <td>14.035298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Acc Gap Mean  Acc Test Max  Acc Test Mean  Acc Test Min  \\\n",
       "1598974549.467531         -0.007         0.905          0.905         0.905   \n",
       "1598974548.179845         -0.016         0.880          0.880         0.880   \n",
       "1598974547.04371           0.075         0.750          0.750         0.750   \n",
       "1598974545.712321          0.070         0.745          0.745         0.745   \n",
       "1598974542.469734          0.069         0.745          0.745         0.745   \n",
       "1598974545.1420789         0.066         0.740          0.740         0.740   \n",
       "1598974544.1796732         0.059         0.735          0.735         0.735   \n",
       "1598974542.7061949         0.059         0.735          0.735         0.735   \n",
       "1598974543.313955          0.059         0.735          0.735         0.735   \n",
       "1598974550.4215832        -0.062         0.645          0.645         0.645   \n",
       "\n",
       "                    Acc Train Max  Acc Train Mean  Acc Train Min  \\\n",
       "1598974549.467531           0.912           0.912          0.912   \n",
       "1598974548.179845           0.896           0.896          0.896   \n",
       "1598974547.04371            0.675           0.675          0.675   \n",
       "1598974545.712321           0.675           0.675          0.675   \n",
       "1598974542.469734           0.676           0.676          0.676   \n",
       "1598974545.1420789          0.674           0.674          0.674   \n",
       "1598974544.1796732          0.676           0.676          0.676   \n",
       "1598974542.7061949          0.676           0.676          0.676   \n",
       "1598974543.313955           0.676           0.676          0.676   \n",
       "1598974550.4215832          0.707           0.707          0.707   \n",
       "\n",
       "                    Loss Test Max  Loss Test Mean  Loss Test Min  \\\n",
       "1598974549.467531        0.254933        0.254933       0.254933   \n",
       "1598974548.179845        0.292642        0.292642       0.292642   \n",
       "1598974547.04371         0.490035        0.490035       0.490035   \n",
       "1598974545.712321        0.492654        0.492654       0.492654   \n",
       "1598974542.469734        0.500382        0.500382       0.500382   \n",
       "1598974545.1420789       0.493422        0.493422       0.493422   \n",
       "1598974544.1796732       0.494121        0.494121       0.494121   \n",
       "1598974542.7061949       0.498270        0.498270       0.498270   \n",
       "1598974543.313955        0.495550        0.495550       0.495550   \n",
       "1598974550.4215832       0.575710        0.575710       0.575710   \n",
       "\n",
       "                    Loss Train Max  Loss Train Mean  Loss Train Min  \\\n",
       "1598974549.467531         0.246102         0.246102        0.246102   \n",
       "1598974548.179845         0.271134         0.271134        0.271134   \n",
       "1598974547.04371          0.547508         0.547508        0.547508   \n",
       "1598974545.712321         0.549718         0.549718        0.549718   \n",
       "1598974542.469734         0.554991         0.554991        0.554991   \n",
       "1598974545.1420789        0.549122         0.549122        0.549122   \n",
       "1598974544.1796732        0.549191         0.549191        0.549191   \n",
       "1598974542.7061949        0.551775         0.551775        0.551775   \n",
       "1598974543.313955         0.549952         0.549952        0.549952   \n",
       "1598974550.4215832        0.522428         0.522428        0.522428   \n",
       "\n",
       "                     Norm Max  Norm Mean   Norm Min learning_rate  \n",
       "1598974549.467531   10.941703  10.941703  10.941703      0.599484  \n",
       "1598974548.179845    7.752036   7.752036   7.752036      0.359381  \n",
       "1598974547.04371     4.784381   4.784381   4.784381      0.215443  \n",
       "1598974545.712321    4.340151   4.340151   4.340151      0.129155  \n",
       "1598974542.469734    2.882570   2.882570   2.882570          0.01  \n",
       "1598974545.1420789   4.016640   4.016640   4.016640     0.0774264  \n",
       "1598974544.1796732   3.737629   3.737629   3.737629     0.0464159  \n",
       "1598974542.7061949   3.169239   3.169239   3.169239      0.016681  \n",
       "1598974543.313955    3.462085   3.462085   3.462085     0.0278256  \n",
       "1598974550.4215832  14.035298  14.035298  14.035298             1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.sort_values(by=\"Acc Test Max\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = get_all_models(experiment_folder, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = all_models[\"1598974549.467531\"][\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2658, -0.6265],\n",
       "        [ 0.2988,  0.1844]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(m.state_dict())['fc_final.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc_input.weight', tensor([[ 2.9696,  2.7813],\n",
       "                      [-2.0304, -4.5138]])),\n",
       "             ('fc_input.bias', tensor([1.0918, 0.4376])),\n",
       "             ('layers.0.weight', tensor([[1.9712, 1.5252],\n",
       "                      [1.0219, 0.7898]])),\n",
       "             ('layers.0.bias', tensor([-7.1405, -3.7015])),\n",
       "             ('fc_final.weight', tensor([[-1.2658, -0.6265],\n",
       "                      [ 0.2988,  0.1844]])),\n",
       "             ('fc_final.bias', tensor([ 1.4916, -0.7878]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def last_layer_net(m):\n",
    "    new_m = copy.deepcopy(m)\n",
    "    \n",
    "    param_dict = dict(m.state_dict())\n",
    "    new_final_weight = torch.eye(param_dict['fc_final.weight'].shape[1])\n",
    "    new_final_bias =  torch.zeros(param_dict['fc_final.weight'].shape[1])\n",
    "    \n",
    "    \n",
    "    return new_m\n",
    "\n",
    "last_layer_net(m).state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
