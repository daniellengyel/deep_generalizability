{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle,os, copy\n",
    "os.environ[\"PATH_TO_DEEP_FOLDER\"] = \"/rds/general/user/dl2119/home/deep_generalizability\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "import re\n",
    "\n",
    "import margin_flatness as mf\n",
    "import margin_flatness.postprocessing as mf_post\n",
    "\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (13,9)\n",
    "\n",
    "COLORS = plt.cm.tab20(np.arange(20))\n",
    "\n",
    "CORRECT_COLOR_IDX = 3\n",
    "INCORRECT_COLOR_IDX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = os.environ[\"PATH_TO_DEEP_FOLDER\"]\n",
    "data_name = \"CIFAR10\"\n",
    "\n",
    "exp_name = \"\"\n",
    "\n",
    "exp_name = \"LeNet_short\" #\"May19_00-32-38_cx3-7-9.cx3.hpc.ic.ac.uk\"\n",
    "experiment_folder = os.path.join(root_folder, \"experiments\", data_name, exp_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = mf_post.stats_plotting.get_end_stats(experiment_folder, step=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Acc Test Mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f3cb060cd12b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstats_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Acc Test Mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deep_gen/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   5453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5454\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5455\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5457\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_gen/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1682\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Acc Test Mean'"
     ]
    }
   ],
   "source": [
    "stats_df.sort_values(by=\"Acc Test Mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cached data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf.save_load.join_cached_sub_data(experiment_folder, \"point_traces\", -1, \"May18_23-54-38\")\n",
    "# mf.save_load.join_cached_sub_data(experiment_folder, \"point_loss\", -1, \"May18_23-54-28\")\n",
    "# mf.save_load.join_cached_sub_data(experiment_folder, \"inp_out_jacobian\", -1, \"May18_23-58-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_point_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_point_traces, _ = mf.save_load.load_cached_data(experiment_folder, \"point_traces\", step=-1, time_stamp=\"May25_16-21-58-862654-joined\")\n",
    "# all_point_loss, _ = mf.save_load.load_cached_data(experiment_folder, \"point_loss\", step=-1, time_stamp=\"May25_17-48-36-470248-joined\")\n",
    "inp_out_jacobian, _ = mf.save_load.load_cached_data(experiment_folder, \"inp_out_jacobian\", step=-1, time_stamp=\"May25_16-19-33-203813-joined\")\n",
    "# output_margins, _ = mf.save_load.load_cached_data(experiment_folder, \"output_margins\", step=-1, time_stamp=\"May25_15-00-54-625745-joined\")\n",
    "\n",
    "# post_dict = {\"traces\": all_point_traces, \"losses\": all_point_loss, \"jacobian\": inp_out_jacobian, \"margins\": output_margins}\n",
    "post_dict = {\"traces\": all_point_traces, \"jacobian\": inp_out_jacobian,}\n",
    "\n",
    "train_loss_acc, _ = mf.save_load.load_cached_data(experiment_folder, \"model_loss_acc\", step=-1, time_stamp=\"May25_14-28-14-776489-joined\")\n",
    "test_loss_acc, _ = mf.save_load.load_cached_data(experiment_folder, \"model_loss_acc\", step=-1, time_stamp=\"May25_14-28-14-733072-joined\")\n",
    "loss_acc_dict = {k: {\"acc_train\": train_loss_acc[k][1]['0'], \"acc_test\": test_loss_acc[k][1]['0'], \"loss_train\": train_loss_acc[k][0]['0'], \"loss_test\": test_loss_acc[k][0]['0']} for k in train_loss_acc}\n",
    "loss_acc_df = pd.DataFrame(data=loss_acc_dict.values(), index=loss_acc_dict.keys())\n",
    "\n",
    "# loss_acc_dict = {losses: }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get processed DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_kendalls(exp_post_dict, exp_ids, configs):\n",
    "    kendall_coeffs = {}\n",
    "    \n",
    "    for k1 in exp_post_dict.keys():\n",
    "        for k2 in exp_post_dict.keys():\n",
    "            # We continue since kendall is symmetric\n",
    "            if (k2, k1) in kendall_coeffs or k1 == k2:\n",
    "                continue\n",
    "            kendall_coeffs[(k1, k2)] = {}\n",
    "\n",
    "            for exp_id in exp_ids:\n",
    "                kendall_coeffs[(k1, k2)][exp_id] = mf_post.correlation.get_kendall(exp_post_dict[k1][exp_id]['0'], exp_post_dict[k2][exp_id]['0'], remove_outliers=True).correlation\n",
    "    \n",
    "    hp_df = get_hp_df(configs)        \n",
    "    kendall_coeffs_df = pd.DataFrame(kendall_coeffs)\n",
    "    return pd.concat([kendall_coeffs_df, hp_df], axis=1)\n",
    "\n",
    "\n",
    "def get_all_r2(exp_post_dict, exp_ids, configs):\n",
    "    r2_coeffs = {}\n",
    "    \n",
    "    for k1 in exp_post_dict.keys():\n",
    "        for k2 in exp_post_dict.keys():\n",
    "            # We continue only if equal. r2 is not symmetric, so we get the max\n",
    "            if k1 == k2:\n",
    "                continue\n",
    "            \n",
    "            if (k1, k2) not in r2_coeffs:\n",
    "                r2_coeffs[(k1, k2)] = {}\n",
    "\n",
    "            for exp_id in exp_ids:\n",
    "                if (k2, k1) in r2_coeffs:\n",
    "                    try:\n",
    "                        r2_coeffs[(k2, k1)][exp_id] = max(r2_coeffs[(k2, k1)][exp_id], mf_post.correlation.get_isotonic_r_squared(exp_post_dict[k1][exp_id]['0'], exp_post_dict[k2][exp_id]['0'], remove_outliers=True, increasing=\"auto\"))\n",
    "                    except:\n",
    "                        pass\n",
    "                else:\n",
    "                    try:\n",
    "                        r2_coeffs[(k1, k2)][exp_id] = mf_post.correlation.get_isotonic_r_squared(exp_post_dict[k1][exp_id]['0'], exp_post_dict[k2][exp_id]['0'], remove_outliers=True, increasing=\"auto\") \n",
    "                    except:\n",
    "                        r2_coeffs[(k1, k2)][exp_id] = np.nan\n",
    "            \n",
    "    hp_df = get_hp_df(configs)        \n",
    "    r2_coeffs_df = pd.DataFrame(r2_coeffs)\n",
    "    return pd.concat([r2_coeffs_df, hp_df], axis=1)\n",
    "\n",
    "\n",
    "def get_hp_df(configs):\n",
    "    cfs_hp = mf_post.utils.get_hp(configs)\n",
    "    cfs_hp_df = configs[list(cfs_hp.keys())]\n",
    "    return cfs_hp_df\n",
    "\n",
    "cfgs = mf.save_load.load_configs(experiment_folder)\n",
    "exp_ids = list(cfgs.index)\n",
    "# exp_ids = [\"1621270824.0509984\"]\n",
    "kendall_df = get_all_kendalls(post_dict, exp_ids, cfgs)\n",
    "r2_df = get_all_r2(post_dict, exp_ids, cfgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_filter(df, config_subset):\n",
    "    index_filter = [True] * len(df)\n",
    "    for k, v in config_subset.items():\n",
    "        index_filter = index_filter & (df[k] == v)\n",
    "    return index_filter\n",
    "\n",
    "def subset_df(df, p_types, config_subset):\n",
    "    index_filter = [True] * len(df)\n",
    "    for k, v in config_subset.items():\n",
    "        index_filter = index_filter & (df[k] == v)\n",
    "            \n",
    "    if len(p_types) == 1:\n",
    "        return df[df.columns[[p_types[0] in c for c in df.columns]]][index_filter]\n",
    "    \n",
    "    col_filter = []\n",
    "    for c in df.columns:\n",
    "        if c[0] in p_types and c[1] in p_types:\n",
    "            col_filter.append(True)\n",
    "        else:\n",
    "            col_filter.append(False)\n",
    "    return df[df.columns[col_filter]][index_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>(traces, jacobian)</th>\n",
       "      <th>(jacobian, traces)</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">MSE</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">Adam</th>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.014688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250667</td>\n",
       "      <td>0.250217</td>\n",
       "      <td>0.088501</td>\n",
       "      <td>0.088548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000005</th>\n",
       "      <td>0.018801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.373533</td>\n",
       "      <td>0.373067</td>\n",
       "      <td>0.078473</td>\n",
       "      <td>0.078768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.028751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422050</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.074241</td>\n",
       "      <td>0.074685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000025</th>\n",
       "      <td>0.047445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>0.460633</td>\n",
       "      <td>0.068279</td>\n",
       "      <td>0.069839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000050</th>\n",
       "      <td>0.061059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.544117</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>0.061690</td>\n",
       "      <td>0.065435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000075</th>\n",
       "      <td>0.064116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577217</td>\n",
       "      <td>0.515867</td>\n",
       "      <td>0.057958</td>\n",
       "      <td>0.063994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSProp</th>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.015437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244367</td>\n",
       "      <td>0.244550</td>\n",
       "      <td>0.088911</td>\n",
       "      <td>0.088949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000005</th>\n",
       "      <td>0.021464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.365150</td>\n",
       "      <td>0.365550</td>\n",
       "      <td>0.079097</td>\n",
       "      <td>0.079384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.021858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413267</td>\n",
       "      <td>0.410683</td>\n",
       "      <td>0.074959</td>\n",
       "      <td>0.075383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000025</th>\n",
       "      <td>0.051635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481733</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.068366</td>\n",
       "      <td>0.069667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000050</th>\n",
       "      <td>0.052506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.529700</td>\n",
       "      <td>0.492800</td>\n",
       "      <td>0.063072</td>\n",
       "      <td>0.066305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000075</th>\n",
       "      <td>0.053000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569250</td>\n",
       "      <td>0.513567</td>\n",
       "      <td>0.058813</td>\n",
       "      <td>0.064120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">SGD</th>\n",
       "      <th>0.005000</th>\n",
       "      <td>0.034619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446067</td>\n",
       "      <td>0.438350</td>\n",
       "      <td>0.071507</td>\n",
       "      <td>0.072030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>0.052732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558900</td>\n",
       "      <td>0.520500</td>\n",
       "      <td>0.060414</td>\n",
       "      <td>0.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.025000</th>\n",
       "      <td>0.042159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693050</td>\n",
       "      <td>0.574567</td>\n",
       "      <td>0.045281</td>\n",
       "      <td>0.058119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.050000</th>\n",
       "      <td>0.054969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.798567</td>\n",
       "      <td>0.583033</td>\n",
       "      <td>0.031763</td>\n",
       "      <td>0.060043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.075000</th>\n",
       "      <td>0.074388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839067</td>\n",
       "      <td>0.579167</td>\n",
       "      <td>0.025140</td>\n",
       "      <td>0.062239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>0.138198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777767</td>\n",
       "      <td>0.549150</td>\n",
       "      <td>0.035536</td>\n",
       "      <td>0.066830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">cross-entropy</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">Adam</th>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.017817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211550</td>\n",
       "      <td>0.215383</td>\n",
       "      <td>2.250505</td>\n",
       "      <td>2.250117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000005</th>\n",
       "      <td>0.112087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315367</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>1.977668</td>\n",
       "      <td>1.978815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.136213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.367583</td>\n",
       "      <td>1.847643</td>\n",
       "      <td>1.850348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000025</th>\n",
       "      <td>0.147698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.423217</td>\n",
       "      <td>1.696455</td>\n",
       "      <td>1.713869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000050</th>\n",
       "      <td>0.211582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465067</td>\n",
       "      <td>0.453450</td>\n",
       "      <td>1.578428</td>\n",
       "      <td>1.617724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000075</th>\n",
       "      <td>0.269281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502450</td>\n",
       "      <td>0.481067</td>\n",
       "      <td>1.472998</td>\n",
       "      <td>1.533974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSProp</th>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.016549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210067</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>2.263718</td>\n",
       "      <td>2.263504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000005</th>\n",
       "      <td>0.082463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.303967</td>\n",
       "      <td>0.305200</td>\n",
       "      <td>2.012627</td>\n",
       "      <td>2.013471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.127591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355517</td>\n",
       "      <td>0.356183</td>\n",
       "      <td>1.874393</td>\n",
       "      <td>1.877171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000025</th>\n",
       "      <td>0.141983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.417017</td>\n",
       "      <td>0.419617</td>\n",
       "      <td>1.710110</td>\n",
       "      <td>1.725340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000050</th>\n",
       "      <td>0.198997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.467617</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>1.582465</td>\n",
       "      <td>1.617514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000075</th>\n",
       "      <td>0.284639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485850</td>\n",
       "      <td>0.464733</td>\n",
       "      <td>1.527748</td>\n",
       "      <td>1.586547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">SGD</th>\n",
       "      <th>0.005000</th>\n",
       "      <td>0.699780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.868800</td>\n",
       "      <td>0.580133</td>\n",
       "      <td>0.396718</td>\n",
       "      <td>1.787874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>0.761365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917650</td>\n",
       "      <td>0.575867</td>\n",
       "      <td>0.234766</td>\n",
       "      <td>2.526071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.025000</th>\n",
       "      <td>0.776170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.921200</td>\n",
       "      <td>0.561767</td>\n",
       "      <td>0.242260</td>\n",
       "      <td>2.907701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.050000</th>\n",
       "      <td>0.699843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.858483</td>\n",
       "      <td>0.541050</td>\n",
       "      <td>0.444945</td>\n",
       "      <td>2.588632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.075000</th>\n",
       "      <td>0.702002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>0.520283</td>\n",
       "      <td>0.757670</td>\n",
       "      <td>2.279251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>2.302668</td>\n",
       "      <td>2.302668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       (traces, jacobian)  (jacobian, traces)  \\\n",
       "criterion     optimizer learning_rate                                           \n",
       "MSE           Adam      0.000001                 0.014688                 NaN   \n",
       "                        0.000005                 0.018801                 NaN   \n",
       "                        0.000010                 0.028751                 NaN   \n",
       "                        0.000025                 0.047445                 NaN   \n",
       "                        0.000050                 0.061059                 NaN   \n",
       "                        0.000075                 0.064116                 NaN   \n",
       "              RMSProp   0.000001                 0.015437                 NaN   \n",
       "                        0.000005                 0.021464                 NaN   \n",
       "                        0.000010                 0.021858                 NaN   \n",
       "                        0.000025                 0.051635                 NaN   \n",
       "                        0.000050                 0.052506                 NaN   \n",
       "                        0.000075                 0.053000                 NaN   \n",
       "              SGD       0.005000                 0.034619                 NaN   \n",
       "                        0.010000                 0.052732                 NaN   \n",
       "                        0.025000                 0.042159                 NaN   \n",
       "                        0.050000                 0.054969                 NaN   \n",
       "                        0.075000                 0.074388                 NaN   \n",
       "                        1.000000                 0.138198                 NaN   \n",
       "cross-entropy Adam      0.000001                 0.017817                 NaN   \n",
       "                        0.000005                 0.112087                 NaN   \n",
       "                        0.000010                 0.136213                 NaN   \n",
       "                        0.000025                 0.147698                 NaN   \n",
       "                        0.000050                 0.211582                 NaN   \n",
       "                        0.000075                 0.269281                 NaN   \n",
       "              RMSProp   0.000001                 0.016549                 NaN   \n",
       "                        0.000005                 0.082463                 NaN   \n",
       "                        0.000010                 0.127591                 NaN   \n",
       "                        0.000025                 0.141983                 NaN   \n",
       "                        0.000050                 0.198997                 NaN   \n",
       "                        0.000075                 0.284639                 NaN   \n",
       "              SGD       0.005000                 0.699780                 NaN   \n",
       "                        0.010000                 0.761365                 NaN   \n",
       "                        0.025000                 0.776170                 NaN   \n",
       "                        0.050000                 0.699843                 NaN   \n",
       "                        0.075000                 0.702002                 NaN   \n",
       "                        1.000000                 1.000000                 NaN   \n",
       "\n",
       "                                       acc_train  acc_test  loss_train  \\\n",
       "criterion     optimizer learning_rate                                    \n",
       "MSE           Adam      0.000001        0.250667  0.250217    0.088501   \n",
       "                        0.000005        0.373533  0.373067    0.078473   \n",
       "                        0.000010        0.422050  0.416800    0.074241   \n",
       "                        0.000025        0.481000  0.460633    0.068279   \n",
       "                        0.000050        0.544117  0.503800    0.061690   \n",
       "                        0.000075        0.577217  0.515867    0.057958   \n",
       "              RMSProp   0.000001        0.244367  0.244550    0.088911   \n",
       "                        0.000005        0.365150  0.365550    0.079097   \n",
       "                        0.000010        0.413267  0.410683    0.074959   \n",
       "                        0.000025        0.481733  0.464400    0.068366   \n",
       "                        0.000050        0.529700  0.492800    0.063072   \n",
       "                        0.000075        0.569250  0.513567    0.058813   \n",
       "              SGD       0.005000        0.446067  0.438350    0.071507   \n",
       "                        0.010000        0.558900  0.520500    0.060414   \n",
       "                        0.025000        0.693050  0.574567    0.045281   \n",
       "                        0.050000        0.798567  0.583033    0.031763   \n",
       "                        0.075000        0.839067  0.579167    0.025140   \n",
       "                        1.000000        0.777767  0.549150    0.035536   \n",
       "cross-entropy Adam      0.000001        0.211550  0.215383    2.250505   \n",
       "                        0.000005        0.315367  0.317783    1.977668   \n",
       "                        0.000010        0.364800  0.367583    1.847643   \n",
       "                        0.000025        0.420833  0.423217    1.696455   \n",
       "                        0.000050        0.465067  0.453450    1.578428   \n",
       "                        0.000075        0.502450  0.481067    1.472998   \n",
       "              RMSProp   0.000001        0.210067  0.213483    2.263718   \n",
       "                        0.000005        0.303967  0.305200    2.012627   \n",
       "                        0.000010        0.355517  0.356183    1.874393   \n",
       "                        0.000025        0.417017  0.419617    1.710110   \n",
       "                        0.000050        0.467617  0.455000    1.582465   \n",
       "                        0.000075        0.485850  0.464733    1.527748   \n",
       "              SGD       0.005000        0.868800  0.580133    0.396718   \n",
       "                        0.010000        0.917650  0.575867    0.234766   \n",
       "                        0.025000        0.921200  0.561767    0.242260   \n",
       "                        0.050000        0.858483  0.541050    0.444945   \n",
       "                        0.075000        0.779200  0.520283    0.757670   \n",
       "                        1.000000        0.104600  0.096400    2.302668   \n",
       "\n",
       "                                       loss_test  \n",
       "criterion     optimizer learning_rate             \n",
       "MSE           Adam      0.000001        0.088548  \n",
       "                        0.000005        0.078768  \n",
       "                        0.000010        0.074685  \n",
       "                        0.000025        0.069839  \n",
       "                        0.000050        0.065435  \n",
       "                        0.000075        0.063994  \n",
       "              RMSProp   0.000001        0.088949  \n",
       "                        0.000005        0.079384  \n",
       "                        0.000010        0.075383  \n",
       "                        0.000025        0.069667  \n",
       "                        0.000050        0.066305  \n",
       "                        0.000075        0.064120  \n",
       "              SGD       0.005000        0.072030  \n",
       "                        0.010000        0.063400  \n",
       "                        0.025000        0.058119  \n",
       "                        0.050000        0.060043  \n",
       "                        0.075000        0.062239  \n",
       "                        1.000000        0.066830  \n",
       "cross-entropy Adam      0.000001        2.250117  \n",
       "                        0.000005        1.978815  \n",
       "                        0.000010        1.850348  \n",
       "                        0.000025        1.713869  \n",
       "                        0.000050        1.617724  \n",
       "                        0.000075        1.533974  \n",
       "              RMSProp   0.000001        2.263504  \n",
       "                        0.000005        2.013471  \n",
       "                        0.000010        1.877171  \n",
       "                        0.000025        1.725340  \n",
       "                        0.000050        1.617514  \n",
       "                        0.000075        1.586547  \n",
       "              SGD       0.005000        1.787874  \n",
       "                        0.010000        2.526071  \n",
       "                        0.025000        2.907701  \n",
       "                        0.050000        2.588632  \n",
       "                        0.075000        2.279251  \n",
       "                        1.000000        2.302668  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "kendall_df_new = pd.concat([kendall_df, loss_acc_df], axis=1)\n",
    "r2_df_new = pd.concat([r2_df, loss_acc_df], axis=1)\n",
    "\n",
    "# kendall_df_new[kendall_df_new[\"optimizer\"] == \"RMSProp\"].sort_values(\"train_loss\")\n",
    "# kendall_df_new.sort_values(\"train_loss\").tail(25)\n",
    "r2_df_new[r2] # .groupby([\"criterion\", \"optimizer\", \"learning_rate\"]).mean()#.sort_values((\"margins\", \"jacobian\"))#.head(50)#[kendall_df_new[\"criterion\"] == \"cross-entropy\"].sort_values((\"traces\", \"losses\"), ascending=False).head(40) # .groupby([\"learning_rate\",\"optimizer\", \"criterion\"]).mean() #.loc[\"1621270824.0509984\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a histogram for kendall and isotonic R^2 value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(traces, jacobian)</th>\n",
       "      <th>(jacobian, traces)</th>\n",
       "      <th>batch_train_size</th>\n",
       "      <th>criterion</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>seed</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1621712994.9740756</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621713086.0385306</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.025</td>\n",
       "      <td>SGD</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621723180.3606398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621723181.7773988</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.005</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621713225.772196</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621713263.2869356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621713060.4051876</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621723280.0908508</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621712996.9256675</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621732589.7689776</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    (traces, jacobian)  (jacobian, traces) batch_train_size  \\\n",
       "1621712994.9740756                 1.0                 NaN              128   \n",
       "1621713086.0385306                 1.0                 NaN              128   \n",
       "1621723180.3606398                 1.0                 NaN              128   \n",
       "1621723181.7773988                 1.0                 NaN              256   \n",
       "1621713225.772196                  1.0                 NaN              256   \n",
       "...                                ...                 ...              ...   \n",
       "1621713263.2869356                 NaN                 NaN              128   \n",
       "1621713060.4051876                 NaN                 NaN              256   \n",
       "1621723280.0908508                 NaN                 NaN              256   \n",
       "1621712996.9256675                 NaN                 NaN              256   \n",
       "1621732589.7689776                 NaN                 NaN              128   \n",
       "\n",
       "                        criterion learning_rate optimizer seed weight_decay  \n",
       "1621712994.9740756  cross-entropy             1       SGD    0            0  \n",
       "1621713086.0385306  cross-entropy         0.025       SGD    5            0  \n",
       "1621723180.3606398  cross-entropy         0.005       SGD   10            0  \n",
       "1621723181.7773988  cross-entropy         0.005       SGD   10            0  \n",
       "1621713225.772196   cross-entropy       0.00005   RMSProp   10            0  \n",
       "...                           ...           ...       ...  ...          ...  \n",
       "1621713263.2869356  cross-entropy      0.000005      Adam    5            0  \n",
       "1621713060.4051876  cross-entropy             1       SGD    5            0  \n",
       "1621723280.0908508  cross-entropy             1       SGD    0       0.0001  \n",
       "1621712996.9256675  cross-entropy             1       SGD    0            0  \n",
       "1621732589.7689776  cross-entropy       0.00001   RMSProp    5       0.0001  \n",
       "\n",
       "[371 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_df.sort_values((\"traces\",\"jacobian\"), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(traces, jacobian)</th>\n",
       "      <th>batch_train_size</th>\n",
       "      <th>criterion</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>seed</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1621786648.2537081</th>\n",
       "      <td>0.920798</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.025</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.155687</td>\n",
       "      <td>3.559229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621786660.9983337</th>\n",
       "      <td>0.908455</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.025</td>\n",
       "      <td>SGD</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.5370</td>\n",
       "      <td>0.254365</td>\n",
       "      <td>3.943879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621786669.1946497</th>\n",
       "      <td>0.063546</td>\n",
       "      <td>256</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.025</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6716</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.046609</td>\n",
       "      <td>0.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621786677.325591</th>\n",
       "      <td>0.911728</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.025</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>0.214393</td>\n",
       "      <td>3.188200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621786689.6460016</th>\n",
       "      <td>0.056168</td>\n",
       "      <td>256</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.025</td>\n",
       "      <td>SGD</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7182</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>0.042699</td>\n",
       "      <td>0.057799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621786712.1640303</th>\n",
       "      <td>0.109219</td>\n",
       "      <td>256</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.025</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>0.042222</td>\n",
       "      <td>0.057079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    (traces, jacobian) batch_train_size      criterion  \\\n",
       "1621786648.2537081            0.920798              256  cross-entropy   \n",
       "1621786660.9983337            0.908455              256  cross-entropy   \n",
       "1621786669.1946497            0.063546              256            MSE   \n",
       "1621786677.325591             0.911728              256  cross-entropy   \n",
       "1621786689.6460016            0.056168              256            MSE   \n",
       "1621786712.1640303            0.109219              256            MSE   \n",
       "\n",
       "                   learning_rate optimizer seed weight_decay  acc_train  \\\n",
       "1621786648.2537081         0.025       SGD    0            0     0.9536   \n",
       "1621786660.9983337         0.025       SGD    5            0     0.9216   \n",
       "1621786669.1946497         0.025       SGD    0            0     0.6716   \n",
       "1621786677.325591          0.025       SGD   10            0     0.9298   \n",
       "1621786689.6460016         0.025       SGD    5            0     0.7182   \n",
       "1621786712.1640303         0.025       SGD   10            0     0.7220   \n",
       "\n",
       "                    acc_test  loss_train  loss_test  \n",
       "1621786648.2537081    0.5624    0.155687   3.559229  \n",
       "1621786660.9983337    0.5370    0.254365   3.943879  \n",
       "1621786669.1946497    0.5460    0.046609   0.061014  \n",
       "1621786677.325591     0.5606    0.214393   3.188200  \n",
       "1621786689.6460016    0.5846    0.042699   0.057799  \n",
       "1621786712.1640303    0.5944    0.042222   0.057079  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_subset = {\"optimizer\": \"SGD\", \"learning_rate\": 0.025, \"batch_train_size\": 256, \"weight_decay\": 0}\n",
    "\n",
    "\"1621786712.1640303\" # MSE\n",
    "\"1621786677.325591\" # SGD\n",
    "kendall_df_new[get_subset_filter(r2_df, config_subset)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x148ae092d1c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "config_subset = {\"criterion\": \"cross-entropy\", \"optimizer\": \"SGD\"}\n",
    "p_types = [\"traces\"]\n",
    "\n",
    "kendall_dict_to_use = subset_df(kendall_df, p_types, config_subset)\n",
    "r2_dict_to_use = subset_df(r2_df, p_types, config_subset)\n",
    "    \n",
    "    \n",
    "kendall_values = list(np.abs(kendall_dict_to_use.values.T))\n",
    "r2_values = list(r2_dict_to_use.values.T)\n",
    "labels = list(kendall_dict_to_use.columns)\n",
    "    \n",
    "sns.set(style=\"ticks\")\n",
    "f, (ax_kendall_hist, ax_r2_hist) = plt.subplots(2, figsize=(16,12))\n",
    "\n",
    "ax_kendall_hist.hist(kendall_values, rwidth=10, bins=np.linspace(-1, 1, 50), alpha=1, label=[\"Kendall: {} {}\".format(l[0], l[1]) for l in labels])\n",
    "ax_kendall_hist.tick_params(axis='both', labelbottom=True, labelsize=30)\n",
    "ax_kendall_hist.set_ylabel(ylabel=\"Count\", fontsize=35)\n",
    "ax_kendall_hist.grid(b=True, which='major')\n",
    "\n",
    "ax_r2_hist.hist(r2_values, rwidth=10, bins=np.linspace(-1, 1, 50), alpha=1, label=[\"R2: {} {}\".format(l[0], l[1]) for l in labels]) # TODO: Messed up due to Nan values. \n",
    "ax_r2_hist.tick_params(axis='both', labelbottom=True, labelsize=30)\n",
    "ax_r2_hist.set_ylabel(ylabel=\"Count\", fontsize=35)\n",
    "ax_r2_hist.grid(b=True, which='major')\n",
    "\n",
    "# ax_r2_hist.set_xlim(-0.2, 0.2)\n",
    "# ax_kendall_hist.set_xlim(-0.2, 0.2)\n",
    "\n",
    "ax_kendall_hist.legend(loc=\"upper left\", fontsize=27) #, bbox_to_anchor=(0.45, 0.95))\n",
    "ax_r2_hist.legend(loc=\"upper left\", fontsize=27) #, bbox_to_anchor=(0.3875, 0.95))\n",
    "\n",
    "\n",
    "# f.savefig(\"../figs/kendall_r2_{}_{}\".format(criterion_type, p_types), dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "criterion_type = \"MSE\"\n",
    "p_types = [\"traces\"]\n",
    "\n",
    "kendall_dict_to_use = subset_df(kendall_df, p_types, criterion_type)\n",
    "r2_dict_to_use = subset_df(r2_df, p_types, criterion_type)\n",
    "    \n",
    "    \n",
    "kendall_values = list(np.abs(kendall_dict_to_use.values.T))\n",
    "r2_values = list(r2_dict_to_use.values.T)\n",
    "labels = list(kendall_dict_to_use.columns)\n",
    "    \n",
    "sns.set(style=\"ticks\")\n",
    "f, (ax_kendall_hist, ax_r2_hist) = plt.subplots(2, figsize=(16,12))\n",
    "\n",
    "ax_kendall_hist.hist(kendall_values, rwidth=10, bins=np.linspace(-1, 1, 50), alpha=1, label=[\"Kendall: {} {}\".format(l[0], l[1]) for l in labels])\n",
    "ax_kendall_hist.tick_params(axis='both', labelbottom=True, labelsize=30)\n",
    "ax_kendall_hist.set_ylabel(ylabel=\"Count\", fontsize=35)\n",
    "ax_kendall_hist.grid(b=True, which='major')\n",
    "\n",
    "ax_r2_hist.hist(r2_values, rwidth=10, bins=np.linspace(-1, 1, 50), alpha=1, label=[\"R2: {} {}\".format(l[0], l[1]) for l in labels])\n",
    "ax_r2_hist.tick_params(axis='both', labelbottom=True, labelsize=30)\n",
    "ax_r2_hist.set_ylabel(ylabel=\"Count\", fontsize=35)\n",
    "ax_r2_hist.grid(b=True, which='major')\n",
    "\n",
    "# ax_r2_hist.set_xlim(-0.2, 0.2)\n",
    "# ax_kendall_hist.set_xlim(-0.2, 0.2)\n",
    "\n",
    "ax_kendall_hist.legend(loc=\"upper left\", fontsize=27) #, bbox_to_anchor=(0.45, 0.95))\n",
    "ax_r2_hist.legend(loc=\"upper left\", fontsize=27) #, bbox_to_anchor=(0.3875, 0.95))\n",
    "\n",
    "\n",
    "# f.savefig(\"../figs/kendall_r2_{}_{}\".format(criterion_type, p_types), dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Plot non-aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_df[r2_df[\"criterion\"] == \"MSE\"].sort_values((\"traces\", \"jacobian\"), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_dict = post_dict\n",
    "\n",
    "x_type = \"traces\"\n",
    "y_type = \"jacobian\"\n",
    "exp_id = \"1621786712.1640303\"\n",
    "exp_id = \"1621786648.2537081\" # CE\n",
    "with_isotonic = False\n",
    "\n",
    "# print(np.mean(exp_dict[\"losses\"][exp_id]['0']))\n",
    "    \n",
    "x_data = exp_dict[x_type][exp_id]['0']\n",
    "y_data = exp_dict[y_type][exp_id]['0'] # exp_dict[y_type][exp_id]['0']\n",
    "    \n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "f, ax1 = plt.subplots(1, figsize=(20,12))\n",
    "sns.scatterplot(x=x_data, y=y_data, ax=ax1) #, label=\"Kendall Coeff: {:.2f}\".format(exp_kendall))\n",
    "if with_isotonic:\n",
    "    iso_reg = IsotonicRegression(increasing=\"auto\").fit(x_data, y_data)\n",
    "    y_predicted = iso_reg.predict(x_data)\n",
    "    sns.scatterplot(x=x_data, y=y_predicted, ax=ax1)\n",
    "    \n",
    "ax1.set_ylabel(ylabel=y_type, fontsize=35)\n",
    "ax1.set_xlabel(xlabel=x_type, fontsize=35)\n",
    "ax1.tick_params(axis='both', labelbottom=True, labelsize=30)\n",
    "\n",
    "# ax1.set_ylim(-250, 3500)\n",
    "ax1.grid(b=True, which='major')\n",
    "# ax1.text(x=0.99, y=0.04, transform=ax1.transAxes, s=\"Kendall Coeff: {:.2f}\".format(exp_kendall) ,\\\n",
    "#          fontsize=22, verticalalignment='top', horizontalalignment='right',\\\n",
    "#         backgroundcolor='white', color=c2)\n",
    "\n",
    "\n",
    "# axins2 = inset_axes(ax1, width=4, height=4, loc=1)\n",
    "# sns.scatterplot(x=x_data, y=y_data, ax=axins2)\n",
    "\n",
    "# # sub region of the original image\n",
    "# x1, x2, y1, y2 = 10, 16, -0.6, 1\n",
    "# axins2.set_xlim(x1, x2)\n",
    "# axins2.set_ylim(y1, y2)\n",
    "\n",
    "# # draw a bbox of the region of the inset axes in the parent axes and\n",
    "# # connecting lines between the bbox and the inset axes area\n",
    "# mark_inset(ax1, axins2, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f.savefig(os.path.join(root_folder, \"figs\", \"scatter_{}_{}_{}_{}.png\".format(\"CE\", exp_id, data_name, exp_name)), dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Plot : Aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregation(exp_post_dict, exp_ids):\n",
    "    res_dict = {}\n",
    "    for k in exp_post_dict:\n",
    "        res_dict[k] = {\"mean\": {}, \"max\": {}, \"min\": {}}\n",
    "        for exp_id in exp_ids:\n",
    "            res_dict[k][\"mean\"][exp_id] = np.mean(exp_post_dict[k][exp_id]['0'])\n",
    "            res_dict[k][\"max\"][exp_id] = np.max(exp_post_dict[k][exp_id]['0'])\n",
    "            res_dict[k][\"min\"][exp_id] = np.min(exp_post_dict[k][exp_id]['0'])\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_post_data_vals(data_type, data_subtype, post_dict, acc_dict, exp_id):\n",
    "    exp_ids = list(acc_dict.keys())\n",
    "    assert data_type in post_dict or data_type == \"acc\"    \n",
    "    if \"acc\" != data_type:\n",
    "        return post_dict[data_type][data_subtype][exp_id]\n",
    "    else:\n",
    "        if x_subtype == \"test\":\n",
    "            return acc_dict[exp_id]['0'][1]\n",
    "        else:\n",
    "            return acc_dict[exp_id]['0'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dict = ce_dict\n",
    "exp_ids = ce_stats_df.index\n",
    "agg_dict = get_aggregation(exp_dict,  exp_ids)\n",
    "acc_dict = ce_acc\n",
    "\n",
    "x_type = \"traces\"\n",
    "x_subtype = \"mean\"\n",
    "y_type = \"acc\"\n",
    "y_subtype = \"test\"\n",
    "\n",
    "with_isotonic = True\n",
    "\n",
    "\n",
    "x_data, y_data = [], []\n",
    "\n",
    "for exp_id in exp_ids:\n",
    "    x_data.append(get_post_data_vals(x_type, x_subtype, agg_dict, acc_dict, exp_id))\n",
    "    y_data.append(get_post_data_vals(y_type, y_subtype, agg_dict, acc_dict, exp_id))\n",
    "\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "f, ax1 = plt.subplots(1, figsize=(16,12))\n",
    "sns.scatterplot(x=x_data, y=y_data, ax=ax1) #, label=\"Kendall Coeff: {:.2f}\".format(exp_kendall))\n",
    "# if with_isotonic:\n",
    "#     iso_reg = IsotonicRegression(increasing=\"auto\").fit(x_data, y_data)\n",
    "#     y_predicted = iso_reg.predict(x_data)\n",
    "#     sns.scatterplot(x=x_data, y=y_predicted, ax=ax1)\n",
    "    \n",
    "ax1.set_ylabel(ylabel=y_type, fontsize=22)\n",
    "ax1.set_xlabel(xlabel=x_type, fontsize=22)\n",
    "# ax1.set_ylim(-250, 3500)\n",
    "ax1.grid(b=True, which='major')\n",
    "# ax1.text(x=0.99, y=0.04, transform=ax1.transAxes, s=\"Kendall Coeff: {:.2f}\".format(exp_kendall) ,\\\n",
    "#          fontsize=22, verticalalignment='top', horizontalalignment='right',\\\n",
    "#         backgroundcolor='white', color=c2)\n",
    "\n",
    "\n",
    "# f.savefig(\"../figs/subset_kendall_{}_{}_{}\".format(id_type, data_name, ce_exp), dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot every point on one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_points(exp_post_dict, exp_ids, x_type, y_type, use_isotonic=False, keep_kendall_threshold=0.3): \n",
    "    x_res_arr, y_res_arr = [], []\n",
    "    for exp_id in exp_ids:\n",
    "        x_data = exp_post_dict[x_type][exp_id]['0']\n",
    "        y_data = exp_post_dict[y_type][exp_id]['0']\n",
    "        if use_isotonic:\n",
    "            x_data, y_data = isotonic_outlier_removal(x_data, y_data, 0.02)\n",
    "            iso_reg = IsotonicRegression(increasing=\"auto\").fit(x_data, y_data)\n",
    "            y_predicted = iso_reg.predict(x_data)\n",
    "#             y_predicted += (x_data - np.min(x_data)) * 0.00000002 / np.linalg.norm(x_data) * np.linalg.norm(y_data)\n",
    "            x_data = y_predicted\n",
    "        if abs(mf_post.correlation.get_kendall(x_data, y_data).correlation) >= keep_kendall_threshold:\n",
    "            x_res_arr.append(x_data)\n",
    "            y_res_arr.append(y_data)\n",
    "    return np.array(x_res_arr).flatten(), np.array(y_res_arr).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.scatter(x_data, y_data)\n",
    "\n",
    "# iso_reg = IsotonicRegression(increasing=\"auto\").fit(x_data, y_data)\n",
    "# y_predicted = iso_reg.predict(x_data)\n",
    "# plt.scatter(x_data, y_predicted)\n",
    "\n",
    "# mf_post.correlation.linregress_outliers(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_points(exp_post_dict, exp_ids, x_type, y_type, use_isotonic=False, keep_kendall_threshold=0.3): \n",
    "    x_res_arr, y_res_arr = [], []\n",
    "    for exp_id in exp_ids:\n",
    "        x_data = exp_post_dict[x_type][exp_id]['0']\n",
    "        y_data = exp_post_dict[y_type][exp_id]['0']\n",
    "        if use_isotonic:\n",
    "            x_data, y_data = isotonic_outlier_removal(x_data, y_data, 0.02)\n",
    "            iso_reg = IsotonicRegression(increasing=\"auto\").fit(x_data, y_data)\n",
    "            y_predicted = iso_reg.predict(x_data)\n",
    "#             y_predicted += (x_data - np.min(x_data)) * 0.00000002 / np.linalg.norm(x_data) * np.linalg.norm(y_data)\n",
    "            x_data = y_predicted\n",
    "        if abs(mf_post.correlation.get_kendall(x_data, y_data).correlation) >= keep_kendall_threshold:\n",
    "            x_res_arr.append(x_data)\n",
    "            y_res_arr.append(y_data)\n",
    "    return np.array(x_res_arr).flatten(), np.array(y_res_arr).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_type = \"MSE\"\n",
    "x_type = \"traces\"\n",
    "y_type = \"jacobian\"\n",
    "do_isotonic = False\n",
    "\n",
    "if loss_type == \"CE\":\n",
    "    exp_name = ce_exp\n",
    "    exp_ids = ce_stats_df.index\n",
    "    x_data, y_data = get_all_points(ce_dict, exp_ids, x_type, y_type, use_isotonic=do_isotonic, keep_kendall_threshold=0)\n",
    "else:\n",
    "    exp_name = mse_exp\n",
    "    exp_ids = mse_stats_df.index\n",
    "    x_data, y_data = get_all_points(mse_dict, exp_ids, x_type, y_type, use_isotonic=do_isotonic, keep_kendall_threshold=-1)\n",
    "    \n",
    "c1 = [1.        , 0.49803922, 0.05490196, 1.        ]\n",
    "c2 = [0.12156863, 0.46666667, 0.70588235, 1.        ]\n",
    "\n",
    "\n",
    "f, ax1 = plt.subplots(1, figsize=(24,12))\n",
    "\n",
    "\n",
    "sns.scatterplot(x=x_data, y=y_data, ax=ax1, label=\"Kendall Coeff: {:.2f} \\nR2 score: {:.2f}\".format(mf_post.correlation.get_kendall(y_data, x_data).correlation, mf_post.correlation.get_isotonic_r_squared(y_data, x_data)))\n",
    "\n",
    "ax1.tick_params(axis='both', labelbottom=True, labelsize=30)\n",
    "\n",
    "ax1.set_ylabel(ylabel=y_type, fontsize=35)\n",
    "if do_isotonic:\n",
    "    ax1.set_xlabel(xlabel=\"g_theta({})\".format(x_type), fontsize=35)\n",
    "else:\n",
    "    ax1.set_xlabel(xlabel=\"{}\".format(x_type), fontsize=35)\n",
    "ax1.legend(loc=\"best\", fontsize=32) #, bbox_to_anchor=(0.3875, 0.95))\n",
    "ax1.grid(b=True, which='major')\n",
    "\n",
    "\n",
    "\n",
    "# ax1.text(x=0.99, y=0.9, transform=ax1.transAxes, s=\"Kendall Coeff: {:.2f} \\n R2 score: {:.2f}\".format(mf_post.correlation.get_kendall(y_data, x_data).correlation, mf_post.correlation.get_isotonic_r_squared(y_data, x_data)) ,\\\n",
    "#          fontsize=30, verticalalignment='top', horizontalalignment='right',\\\n",
    "#         backgroundcolor='white', color=c2)\n",
    "\n",
    "# iso_reg = IsotonicRegression(increasing=\"auto\").fit(x_data, y_data)\n",
    "# y_predicted = iso_reg.predict(x_data)\n",
    "# sns.scatterplot(x=x_data, y=y_predicted, ax=ax1, color=\"red\")\n",
    "\n",
    "\n",
    "if loss_type == \"CE\" and y_type == \"traces\":\n",
    "    axins2 = inset_axes(ax1, width=4, height=4, loc=2)\n",
    "    sns.scatterplot(x=x_data, y=y_data, ax=axins2)\n",
    "\n",
    "    # sub region of the original image\n",
    "    x1, x2, y1, y2 = -1000, 5000, -1000, 5000\n",
    "    \n",
    "    axins2.set_xlim(x1, x2)\n",
    "    axins2.set_ylim(y1, y2)\n",
    "\n",
    "    # draw a bbox of the region of the inset axes in the parent axes and\n",
    "    # connecting lines between the bbox and the inset axes area\n",
    "    mark_inset(ax1, axins2, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "#     axins2.tick_params(None) # TODO unset tick_params\n",
    "\n",
    "\n",
    "\n",
    "f.savefig(\"../figs/all_points_{}_{}_{}_{}\".format(loss_type, x_type, y_type, do_isotonic), dpi=300, bbox_inches = \"tight\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using with Isotonic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "def get_outlier_filter(x_data, y_data):\n",
    "    x_data, y_data = np.array(x_data), np.array(y_data)\n",
    "    #     if len(x_data) < 5:\n",
    "    #         return np.array([True]*len(x_data)) # They are all outliers since we don't have enough datapoints\n",
    "    combined_data = np.concatenate([x_data.reshape(len(x_data), 1), y_data.reshape(len(y_data), 1)], axis=1)\n",
    "\n",
    "    clf = LocalOutlierFactor(n_neighbors=10, contamination=0.1)\n",
    "    outlier_filter = clf.fit_predict(combined_data) == 1\n",
    "\n",
    "       \n",
    "    return x_data[outlier_filter], y_data[outlier_filter]\n",
    "\n",
    "# get_outlier_filter(np.array(x_data), np.array(y_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot accuracy vs correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_all_point_traces, _ = mf.save_load.load_cached_data(ce_experiment_folder, \"point_traces\", step=-1, time_stamp=\"Dec02_14-40-03\")\n",
    "ce_all_point_output_margins, _ = mf.save_load.load_cached_data(ce_experiment_folder, \"output_margins\", step=-1, time_stamp=\"Dec02_20-51-39\")\n",
    "\n",
    "\n",
    "mse_all_point_traces, _ = mf.save_load.load_cached_data(mse_experiment_folder, \"point_traces\", step=-1, time_stamp=\"Dec02_14-40-03\")\n",
    "mse_all_point_output_margins, _ = mf.save_load.load_cached_data(mse_experiment_folder, \"output_margins\", step=-1, time_stamp=\"Dec02_18-53-57\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nets = 1\n",
    "\n",
    "ce_kendall_coeffs_train_acc_dict = {}\n",
    "ce_kendall_coeffs_test_acc_dict = {}\n",
    "for exp_id in ce_stats_df.index:\n",
    "    for nn_idx in range(num_nets):\n",
    "        x_data = ce_all_point_traces[exp_id][\"{}\".format(nn_idx)]\n",
    "        y_data = ce_all_point_output_margins[exp_id][\"{}\".format(nn_idx)]\n",
    "        ce_kendall_coeffs_train_acc_dict[exp_id] = (mf_post.correlation.get_kendall(x_data, y_data, remove_outliers=True).correlation, ce_stats_df[\"Acc Train Mean\"][exp_id])\n",
    "        ce_kendall_coeffs_test_acc_dict[exp_id] = (mf_post.correlation.get_kendall(x_data, y_data, remove_outliers=True).correlation, ce_stats_df[\"Acc Test Mean\"][exp_id])\n",
    "\n",
    "mse_kendall_coeffs_train_acc_dict = {}\n",
    "mse_kendall_coeffs_test_acc_dict = {}\n",
    "for exp_id in mse_stats_df.index:\n",
    "    for nn_idx in range(num_nets):\n",
    "        x_data = mse_all_point_traces[exp_id][\"{}\".format(nn_idx)]\n",
    "        y_data = mse_all_point_output_margins[exp_id][\"{}\".format(nn_idx)]\n",
    "        mse_kendall_coeffs_train_acc_dict[exp_id] = (mf_post.correlation.get_kendall(x_data, y_data, remove_outliers=True).correlation, mse_stats_df[\"Acc Train Mean\"][exp_id])\n",
    "        mse_kendall_coeffs_test_acc_dict[exp_id] = (mf_post.correlation.get_kendall(x_data, y_data, remove_outliers=True).correlation, mse_stats_df[\"Acc Test Mean\"][exp_id])\n",
    "\n",
    "ce_kendall_coeffs_train_acc_arr = np.array(list(ce_kendall_coeffs_train_acc_dict.values()))\n",
    "mse_kendall_coeffs_train_acc_arr = np.array(list(mse_kendall_coeffs_train_acc_dict.values()))\n",
    "ce_kendall_coeffs_test_acc_arr = np.array(list(ce_kendall_coeffs_test_acc_dict.values()))\n",
    "mse_kendall_coeffs_test_acc_arr = np.array(list(mse_kendall_coeffs_test_acc_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "f, (ax1_hist) = plt.subplots(1, figsize=(16,12))\n",
    "\n",
    "ax1_hist.hist([ce_kendall_coeffs_train_acc_arr[:, 1], mse_kendall_coeffs_train_acc_arr[:, 1]], color=['darkblue','orange'], alpha=0.5, label=[\"Cross Entropy\", \"MSE\"])\n",
    "\n",
    "ax1_hist.grid(b=True, which='major')\n",
    "\n",
    "ax1_hist.tick_params(axis='both', labelbottom=True, labelsize=18)\n",
    "\n",
    "ax1_hist.set_ylabel(ylabel=\"Training Accuracy\", fontsize=22)\n",
    "\n",
    "ax1_hist.set_ylabel(ylabel=\"Count\", fontsize=22)\n",
    "\n",
    "f.legend(loc=\"upper right\", fontsize=20, bbox_to_anchor=(0.35, 0.88))\n",
    "\n",
    "f.savefig(\"../figs/train_acc\", dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "f, (ax1_hist) = plt.subplots(1, figsize=(16,12))\n",
    "\n",
    "ax1_hist.hist([ce_kendall_coeffs_test_acc_arr[:, 1], mse_kendall_coeffs_test_acc_arr[:, 1]], color=['darkblue','orange'], alpha=0.5, label=[\"Cross Entropy\", \"MSE\"])\n",
    "\n",
    "ax1_hist.grid(b=True, which='major')\n",
    "\n",
    "ax1_hist.tick_params(axis='both', labelbottom=True, labelsize=18)\n",
    "\n",
    "ax1_hist.set_ylabel(ylabel=\"Test Accuracy\", fontsize=22)\n",
    "\n",
    "ax1_hist.set_ylabel(ylabel=\"Count\", fontsize=22)\n",
    "\n",
    "f.legend(loc=\"upper right\", fontsize=20, bbox_to_anchor=(0.35, 0.88))\n",
    "\n",
    "f.savefig(\"../figs/test_acc\", dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nets = 1\n",
    "\n",
    "ce_r2_coeffs_point_output = {}\n",
    "for exp_id in ce_stats_df.index:\n",
    "    for nn_idx in range(num_nets):\n",
    "        x_data = np.array(ce_all_point_traces[exp_id][\"{}\".format(nn_idx)])\n",
    "        y_data = np.array(ce_all_point_output[exp_id][\"{}\".format(nn_idx)])[:, 0]\n",
    "        ce_r2_coeffs_point_output[exp_id] = mf_post.correlation.get_isotonic_r_squared(x_data, y_data, remove_outliers=True, increasing=\"auto\")\n",
    "\n",
    "\n",
    "ce_r2_coeffs_point_loss = {}\n",
    "for exp_id in ce_stats_df.index:\n",
    "    for nn_idx in range(num_nets):\n",
    "        x_data = ce_all_point_traces[exp_id][\"{}\".format(nn_idx)]\n",
    "        y_data = ce_all_point_loss[exp_id][\"{}\".format(nn_idx)]\n",
    "        ce_r2_coeffs_point_loss[exp_id] = mf_post.correlation.get_isotonic_r_squared(x_data, y_data, remove_outliers=True, increasing=\"auto\")\n",
    "\n",
    "        \n",
    "ce_r2_coeffs_output_margins = {}\n",
    "for exp_id in ce_stats_df.index:\n",
    "    for nn_idx in range(num_nets):\n",
    "        x_data = ce_all_point_traces[exp_id][\"{}\".format(nn_idx)]\n",
    "        y_data = ce_all_point_output_margins[exp_id][\"{}\".format(nn_idx)]\n",
    "        ce_r2_coeffs_output_margins[exp_id] = mf_post.correlation.get_isotonic_r_squared(x_data, y_data, remove_outliers=True, increasing=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nets = 1\n",
    "\n",
    "ce_test_acc_hess = {}\n",
    "for exp_id in ce_stats_df.index:\n",
    "    for nn_idx in range(num_nets):\n",
    "        x_data = np.array(ce_all_point_traces[exp_id][\"{}\".format(nn_idx)])\n",
    "        y_data = np.array(ce_all_point_output[exp_id][\"{}\".format(nn_idx)])[:, 0]\n",
    "        ce_test_acc_hess[exp_id] = [ce_stats_df.loc[exp_id][\"Acc Test Mean\"], np.mean(ce_all_point_loss[exp_id][\"{}\".format(nn_idx)])]\n",
    "\n",
    "ce_test_acc_hess_arr = np.array(list(ce_test_acc_hess.values()))\n",
    "\n",
    "mse_test_acc_hess = {}\n",
    "for exp_id in mse_stats_df.index:\n",
    "    for nn_idx in range(num_nets):\n",
    "        x_data = np.array(mse_all_point_traces[exp_id][\"{}\".format(nn_idx)])\n",
    "#         y_data = np.array(mse_all_point_output[exp_id][\"{}\".format(nn_idx)])[:, 0]\n",
    "        mse_test_acc_hess[exp_id] = [mse_stats_df.loc[exp_id][\"Acc Test Mean\"], np.mean(mse_all_point_loss[exp_id][\"{}\".format(nn_idx)])]#mse_stats_df.loc[exp_id][\"Loss Train Mean\"]] #np.mean(ce_all_point_traces[exp_id][\"{}\".format(nn_idx)])]\n",
    "\n",
    "mse_test_acc_hess_arr = np.array(list(mse_test_acc_hess.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "c1 = [1.        , 0.49803922, 0.05490196, 1.        ]\n",
    "c2 = [0.12156863, 0.46666667, 0.70588235, 1.        ]\n",
    "\n",
    "\n",
    "f, ax1 = plt.subplots(1, figsize=(16,12))\n",
    "\n",
    "x_data = mse_test_acc_hess_arr[:, 1]\n",
    "y_data = mse_test_acc_hess_arr[:, 0]\n",
    "\n",
    "print(mf_post.correlation.get_kendall(x_data, y_data, remove_outliers=True).correlation)\n",
    "print(mf_post.correlation.get_isotonic_r_squared(x_data, y_data, remove_outliers=True, increasing=\"auto\"))\n",
    "sns.scatterplot(x=x_data, y=y_data, ax=ax1) #, label=\"Kendall Coeff: {:.2f}\".format(exp_kendall))\n",
    "\n",
    "# ax1.tick_params(axis='both', labelbottom=True, labelsize=18)\n",
    "\n",
    "ax1.set_ylabel(ylabel=\"Test Acc\", fontsize=22)\n",
    "ax1.set_xlabel(xlabel=\"Hessian Trace\", fontsize=22)\n",
    "# ax1.set_ylim(-250, 3500)\n",
    "\n",
    "\n",
    "# ax1.text(x=0.99, y=0.04, transform=ax1.transAxes, s=\"Kendall Coeff: {:.2f}\".format(exp_kendall) ,\\\n",
    "#          fontsize=22, verticalalignment='top', horizontalalignment='right',\\\n",
    "#         backgroundcolor='white', color=c2)\n",
    "\n",
    "ax1.grid(b=True, which='major')\n",
    "\n",
    "# axins2 = inset_axes(ax1, width=4, height=4, loc=1)\n",
    "# sns.scatterplot(x=x_data, y=y_data, ax=axins2)\n",
    "\n",
    "# # sub region of the original image\n",
    "# x1, x2, y1, y2 = 10, 16, -0.6, 1\n",
    "# axins2.set_xlim(x1, x2)\n",
    "# axins2.set_ylim(y1, y2)\n",
    "\n",
    "# # draw a bbox of the region of the inset axes in the parent axes and\n",
    "# # connecting lines between the bbox and the inset axes area\n",
    "# mark_inset(ax1, axins2, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "\n",
    "#f.legend(loc=\"upper right\", fontsize=20, bbox_to_anchor=(0.4, 0.88))\n",
    "\n",
    "\n",
    "# f.savefig(\"../figs/subset_kendall_{}_{}_{}\".format(id_type, data_name, ce_exp), dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "c1 = [1.        , 0.49803922, 0.05490196, 1.        ]\n",
    "c2 = [0.12156863, 0.46666667, 0.70588235, 1.        ]\n",
    "\n",
    "\n",
    "f, ax1 = plt.subplots(1, figsize=(16,12))\n",
    "\n",
    "x_data = mse_test_acc_hess_arr[:, 1]\n",
    "y_data = mse_test_acc_hess_arr[:, 0]\n",
    "print(mf_post.correlation.get_kendall(x_data, y_data, remove_outliers=True).correlation)\n",
    "print(mf_post.correlation.get_isotonic_r_squared(x_data, y_data, remove_outliers=True, increasing=\"auto\"))\n",
    "sns.scatterplot(x=x_data, y=y_data, ax=ax1) #, label=\"Kendall Coeff: {:.2f}\".format(exp_kendall))\n",
    "\n",
    "# ax1.tick_params(axis='both', labelbottom=True, labelsize=18)\n",
    "\n",
    "ax1.set_ylabel(ylabel=\"Test Acc\", fontsize=22)\n",
    "ax1.set_xlabel(xlabel=\"Hessian Trace\", fontsize=22)\n",
    "# ax1.set_ylim(-250, 3500)\n",
    "\n",
    "\n",
    "# ax1.text(x=0.99, y=0.04, transform=ax1.transAxes, s=\"Kendall Coeff: {:.2f}\".format(exp_kendall) ,\\\n",
    "#          fontsize=22, verticalalignment='top', horizontalalignment='right',\\\n",
    "#         backgroundcolor='white', color=c2)\n",
    "\n",
    "ax1.grid(b=True, which='major')\n",
    "\n",
    "# axins2 = inset_axes(ax1, width=4, height=4, loc=1)\n",
    "# sns.scatterplot(x=x_data, y=y_data, ax=axins2)\n",
    "\n",
    "# # sub region of the original image\n",
    "# x1, x2, y1, y2 = 10, 16, -0.6, 1\n",
    "# axins2.set_xlim(x1, x2)\n",
    "# axins2.set_ylim(y1, y2)\n",
    "\n",
    "# # draw a bbox of the region of the inset axes in the parent axes and\n",
    "# # connecting lines between the bbox and the inset axes area\n",
    "# mark_inset(ax1, axins2, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "\n",
    "#f.legend(loc=\"upper right\", fontsize=20, bbox_to_anchor=(0.4, 0.88))\n",
    "\n",
    "\n",
    "# f.savefig(\"../figs/subset_kendall_{}_{}_{}\".format(id_type, data_name, ce_exp), dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ce_sample_flatness_old, _ = mf.save_load.load_cached_data(ce_experiment_folder, \"sample_average_flatness_pointwise\", step=-1, time_stamp=\"Apr07_18-31-05\")\n",
    "ce_sample_flatness, _ = mf.save_load.load_cached_data(ce_experiment_folder, \"sample_average_flatness_pointwise\", step=-1, time_stamp=\"Apr08_01-23-18\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = list(ce_sample_flatness_old.keys())[0]\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "c1 = [1.        , 0.49803922, 0.05490196, 1.        ]\n",
    "c2 = [0.12156863, 0.46666667, 0.70588235, 1.        ]\n",
    "\n",
    "\n",
    "f, ax1 = plt.subplots(1, figsize=(16,12))\n",
    "\n",
    "x_data = ce_sample_flatness[exp_id]['0']\n",
    "y_data = ce_all_point_traces[exp_id]['0']\n",
    "# y_data = ce_sample_flatness_old[exp_id]['0']\n",
    "print(mf_post.correlation.get_kendall(x_data, y_data, remove_outliers=True).correlation)\n",
    "print(mf_post.correlation.get_isotonic_r_squared(x_data, y_data, remove_outliers=True, increasing=\"auto\"))\n",
    "sns.scatterplot(x=x_data, y=y_data, ax=ax1) #, label=\"Kendall Coeff: {:.2f}\".format(exp_kendall))\n",
    "\n",
    "# ax1.tick_params(axis='both', labelbottom=True, labelsize=18)\n",
    "\n",
    "ax1.set_ylabel(ylabel=\"Test Acc\", fontsize=22)\n",
    "ax1.set_xlabel(xlabel=\"Hessian Trace\", fontsize=22)\n",
    "# ax1.set_ylim(-250, 3500)\n",
    "\n",
    "\n",
    "# ax1.text(x=0.99, y=0.04, transform=ax1.transAxes, s=\"Kendall Coeff: {:.2f}\".format(exp_kendall) ,\\\n",
    "#          fontsize=22, verticalalignment='top', horizontalalignment='right',\\\n",
    "#         backgroundcolor='white', color=c2)\n",
    "\n",
    "ax1.grid(b=True, which='major')\n",
    "\n",
    "# axins2 = inset_axes(ax1, width=4, height=4, loc=1)\n",
    "# sns.scatterplot(x=x_data, y=y_data, ax=axins2)\n",
    "\n",
    "# # sub region of the original image\n",
    "# x1, x2, y1, y2 = 10, 16, -0.6, 1\n",
    "# axins2.set_xlim(x1, x2)\n",
    "# axins2.set_ylim(y1, y2)\n",
    "\n",
    "# # draw a bbox of the region of the inset axes in the parent axes and\n",
    "# # connecting lines between the bbox and the inset axes area\n",
    "# mark_inset(ax1, axins2, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "\n",
    "#f.legend(loc=\"upper right\", fontsize=20, bbox_to_anchor=(0.4, 0.88))\n",
    "\n",
    "\n",
    "# f.savefig(\"../figs/subset_kendall_{}_{}_{}\".format(id_type, data_name, ce_exp), dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nets = 1\n",
    "\n",
    "ce_test_acc_hess = {}\n",
    "for exp_id in ce_stats_df.index:\n",
    "    for nn_idx in range(num_nets):\n",
    "        x_data = np.array(ce_sample_flatness[exp_id][\"{}\".format(nn_idx)])\n",
    "        y_data = np.array(ce_all_point_output[exp_id][\"{}\".format(nn_idx)])[:, 0]\n",
    "        ce_test_acc_hess[exp_id] = [ce_stats_df.loc[exp_id][\"Acc Test Mean\"], np.mean(ce_sample_flatness[exp_id][\"{}\".format(nn_idx)])]\n",
    "\n",
    "ce_test_acc_hess_arr = np.array(list(ce_test_acc_hess.values()))\n",
    "\n",
    "# mse_test_acc_hess = {}\n",
    "# for exp_id in mse_stats_df.index:\n",
    "#     for nn_idx in range(num_nets):\n",
    "#         x_data = np.array(mse_all_point_traces[exp_id][\"{}\".format(nn_idx)])\n",
    "# #         y_data = np.array(mse_all_point_output[exp_id][\"{}\".format(nn_idx)])[:, 0]\n",
    "#         mse_test_acc_hess[exp_id] = [mse_stats_df.loc[exp_id][\"Acc Test Mean\"], mse_stats_df.loc[exp_id][\"Loss Train Mean\"]] #np.mean(ce_all_point_traces[exp_id][\"{}\".format(nn_idx)])]\n",
    "\n",
    "# mse_test_acc_hess_arr = np.array(list(mse_test_acc_hess.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "c1 = [1.        , 0.49803922, 0.05490196, 1.        ]\n",
    "c2 = [0.12156863, 0.46666667, 0.70588235, 1.        ]\n",
    "\n",
    "\n",
    "f, ax1 = plt.subplots(1, figsize=(16,12))\n",
    "\n",
    "x_data = ce_test_acc_hess_arr[:, 1]\n",
    "y_data = ce_test_acc_hess_arr[:, 0]\n",
    "print(mf_post.correlation.get_kendall(x_data, y_data, remove_outliers=True).correlation)\n",
    "print(mf_post.correlation.get_isotonic_r_squared(x_data, y_data, remove_outliers=True, increasing=\"auto\"))\n",
    "sns.scatterplot(x=x_data, y=y_data, ax=ax1) #, label=\"Kendall Coeff: {:.2f}\".format(exp_kendall))\n",
    "\n",
    "# ax1.tick_params(axis='both', labelbottom=True, labelsize=18)\n",
    "\n",
    "ax1.set_ylabel(ylabel=\"Test Acc\", fontsize=22)\n",
    "ax1.set_xlabel(xlabel=\"Hessian Trace\", fontsize=22)\n",
    "# ax1.set_ylim(-250, 3500)\n",
    "\n",
    "\n",
    "# ax1.text(x=0.99, y=0.04, transform=ax1.transAxes, s=\"Kendall Coeff: {:.2f}\".format(exp_kendall) ,\\\n",
    "#          fontsize=22, verticalalignment='top', horizontalalignment='right',\\\n",
    "#         backgroundcolor='white', color=c2)\n",
    "\n",
    "ax1.grid(b=True, which='major')\n",
    "\n",
    "# axins2 = inset_axes(ax1, width=4, height=4, loc=1)\n",
    "# sns.scatterplot(x=x_data, y=y_data, ax=axins2)\n",
    "\n",
    "# # sub region of the original image\n",
    "# x1, x2, y1, y2 = 10, 16, -0.6, 1\n",
    "# axins2.set_xlim(x1, x2)\n",
    "# axins2.set_ylim(y1, y2)\n",
    "\n",
    "# # draw a bbox of the region of the inset axes in the parent axes and\n",
    "# # connecting lines between the bbox and the inset axes area\n",
    "# mark_inset(ax1, axins2, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "\n",
    "#f.legend(loc=\"upper right\", fontsize=20, bbox_to_anchor=(0.4, 0.88))\n",
    "\n",
    "\n",
    "# f.savefig(\"../figs/subset_kendall_{}_{}_{}\".format(id_type, data_name, ce_exp), dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isotonic_outlier_removal(x_data, y_data, percent_outlier_remove=0.05, increasing=\"auto\"):\n",
    "    num_outlier_remove = int(len(x_data)*percent_outlier_remove)\n",
    "    for _ in range(num_outlier_remove):\n",
    "        iso_reg = IsotonicRegression(increasing=increasing).fit(x_data, y_data)\n",
    "        y_predicted = iso_reg.predict(x_data)\n",
    "        idx_max = np.argmax(np.abs(y_predicted - y_data))\n",
    "        x_data = np.delete(x_data, idx_max)\n",
    "        y_data = np.delete(y_data, idx_max)\n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "def get_isotonic_r_squared(x_data, y_data, remove_outliers=False, increasing=False):\n",
    "    if len(x_data) == 0:\n",
    "        return 0, 0, 0, None, None\n",
    "    x_data, y_data = np.array(x_data), np.array(y_data)\n",
    "\n",
    "    if remove_outliers:\n",
    "        outlier_filter = get_outlier_filter(x_data, y_data)\n",
    "        x_data, y_data = x_data[outlier_filter], y_data[outlier_filter]\n",
    "        f\n",
    "    iso_reg = IsotonicRegression(increasing=increasing).fit(x_data, y_data)\n",
    "    y_predicted = iso_reg.predict(x_data)\n",
    "    return r2_score(y_data, y_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "slopes = []\n",
    "weights = []\n",
    "\n",
    "ce_models = mf.save_load.get_all_models(ce_experiment_folder, step=-1, device=None)\n",
    "\n",
    "num_nets = 1\n",
    "\n",
    "ce_all_x_data = []\n",
    "ce_all_y_data = []\n",
    "counter = 0\n",
    "for exp_id in ce_stats_df.index:\n",
    "    if counter > 100:\n",
    "        break\n",
    "    counter += 1\n",
    "    for nn_idx in range(num_nets):\n",
    "        x_data = ce_all_point_traces[exp_id][\"{}\".format(nn_idx)]\n",
    "        y_data = ce_all_point_loss[exp_id][\"{}\".format(nn_idx)] #ce_all_point_output_margins[exp_id][\"{}\".format(nn_idx)]\n",
    "        x_data, y_data = isotonic_outlier_removal(x_data, y_data, 0.02)\n",
    "        iso_reg = IsotonicRegression(increasing=\"auto\").fit(x_data, y_data)\n",
    "        y_predicted = iso_reg.predict(x_data)\n",
    "        y_predicted_org = np.copy(y_predicted)\n",
    "        y_predicted += (x_data - np.min(x_data)) * 0.00002 / np.linalg.norm(x_data) * np.linalg.norm(y_data)\n",
    "\n",
    "        slope, intercept, correct_r_value, _, _ = mf_post.correlation.linregress_outliers(x_data, y_data)\n",
    "        y_lin_predicted = np.array(x_data) * float(slope) + intercept\n",
    "\n",
    "        slopes.append(slope)\n",
    "        weights.append(mf.utils.get_params_norm(ce_models[exp_id][\"0\"]))\n",
    "\n",
    "#         ce_all_x_data.append(np.mean(x_data))\n",
    "#         ce_all_y_data.append(np.max(y_data))\n",
    "        \n",
    "# ce_all_x_data = np.array(ce_all_x_data).flatten()\n",
    "# ce_all_y_data = np.array(ce_all_y_data).flatten()\n",
    "     \n",
    "# exp_name = ce_exp\n",
    "# x_data = ce_all_x_data\n",
    "# y_data = ce_all_y_data\n",
    "\n",
    "\n",
    "    \n",
    "#         c1 = [1.        , 0.49803922, 0.05490196, 1.        ]\n",
    "\n",
    "\n",
    "#         f, ax1 = plt.subplots(1, figsize=(16,12))\n",
    "        \n",
    "#         sns.scatterplot(x=y_lin_predicted, y=y_data)\n",
    "# #         sns.scatterplot(x=x_data, y=y_data)\n",
    "# #         sns.scatterplot(x=y_lin_predicted, y=y_data)\n",
    "# #         sns.scatterplot(x=y_predicted, y=y_data, ax=ax1) #, label=\"Kendall Coeff: {:.2f}\".format(exp_kendall))\n",
    "\n",
    "#         # ax1.tick_params(axis='both', labelbottom=True, labelsize=18)\n",
    "\n",
    "#         ax1.set_ylabel(ylabel=\"Hessian Trace\", fontsize=22)\n",
    "#         ax1.set_xlabel(xlabel=\"Output Margin\", fontsize=22)\n",
    "#         # ax1.set_ylim(-50, 300)\n",
    "        \n",
    "#         print(mf_post.correlation.get_kendall(y_predicted, y_data).correlation)\n",
    "#         print(mf_post.correlation.get_kendall(y_lin_predicted, y_data).correlation)\n",
    "\n",
    "#         print(mf_post.correlation.get_kendall(x_data, y_data).correlation)\n",
    "#         ax1.text(x=0.99, y=0.04, transform=ax1.transAxes, s=\"R2 Score: {:.2f}\".format(r2_score(y_data, y_lin_predicted)) ,\\\n",
    "#              fontsize=22, verticalalignment='top', horizontalalignment='right',\\\n",
    "#             backgroundcolor='white', color=c2)\n",
    "\n",
    "#         ax1.grid(b=True, which='major')\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(slopes, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_nets(m1, m2, N, inp_dim, seed=0):\n",
    "    x = torch.randn(N, inp_dim)\n",
    "    y1 = m1(x)\n",
    "    y2 = m2(x)\n",
    "    diff = torch.norm(y1 - y2, dim=1)\n",
    "    return float(torch.mean(diff).detach().numpy())\n",
    "\n",
    "m1 = ce_models[ce_stats_df.index[0]][\"0\"]\n",
    "m2 = ce_models[ce_stats_df.index[1]][\"0\"]\n",
    "\n",
    "N = 100\n",
    "inp_dim = 28*28\n",
    "\n",
    "# ce_stats_df.index[0]\n",
    "\n",
    "arr_dists = []\n",
    "for i in range(81):\n",
    "    for j in range(i, 81):\n",
    "        arr_dists.append(compare_nets(ce_models[ce_stats_df.index[i]][\"0\"], ce_models[ce_stats_df.index[j]][\"0\"], N, inp_dim, seed=0))\n",
    "\n",
    "# compare_nets(m1, m2, 1000, 28*28)\n",
    "\n",
    "\n",
    "# for exp_id in ce_stats_df.index:\n",
    "#     for exp_id in ce_stats_df.index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "seed = 0\n",
    "num_datapoints = 100\n",
    "\n",
    "# m1 = ce_models[ce_stats_df.index[0]][\"0\"]\n",
    "\n",
    "\n",
    "train_data, test_data = mf.postprocessing.utils.get_data_for_experiment(experiment_folder)\n",
    "data = mf.data_getters.get_random_data_subset(train_data, num_datapoints=num_datapoints, seed=seed)\n",
    "\n",
    "data_loader = DataLoader(data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.eval()\n",
    "\n",
    "res = []\n",
    "\n",
    "m_new = mf.nets.Nets.DanielNormOutputNet(m)\n",
    "\n",
    "for i, (inputs, labels) in enumerate(data_loader):\n",
    "\n",
    "    outputs = m_new(inputs) # get softmax of this \n",
    "    temp_res = []\n",
    "    soft_layer = torch.nn.Softmax(dim=-1)\n",
    "    for a in np.linspace(1, 10):\n",
    "        temp_res.append(max(soft_layer(a*outputs).detach().numpy()[0]))\n",
    "    res.append(temp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_arr = []\n",
    "for i in range(len(res)):\n",
    "    for j in range(i+1, len(res)):\n",
    "        int_arr.append(do_intersect(res[i], res[j]))\n",
    "        if int_arr[-1]:\n",
    "            print(\"{} {}\".format(i, j))\n",
    "        \n",
    "# int_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[48])\n",
    "plt.plot(res[71])\n",
    "# plt.xlim(40, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_dists = np.array([np.array(dict_dists[i]) for i in range(81)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_intersect(res1, res2):\n",
    "    for i in range(len(res1)):\n",
    "        if res1[0] < res2[0]:\n",
    "            if res1[i] > res2[i]:\n",
    "                return True\n",
    "        if res1[0] > res2[0]:\n",
    "            if res1[i] < res2[i]:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "delta = 2\n",
    "for _ in range(100):\n",
    "    a = np.random.random(10)\n",
    "    a[0] = delta*max(a)\n",
    "\n",
    "\n",
    "    res1 = []\n",
    "    for i in np.linspace(0, 100):\n",
    "        o = np.exp(i*a) / np.sum(np.exp(i*a))\n",
    "        res1.append(o.dot(o))\n",
    "\n",
    "    res1 = np.array(res1)\n",
    "\n",
    "\n",
    "    a = np.random.random(10)\n",
    "    a[0] = delta*max(a)\n",
    "\n",
    "    res2 = []\n",
    "    for i in np.linspace(0, 100):\n",
    "        o = np.exp(i*a) / np.sum(np.exp(i*a))\n",
    "        res2.append(o.dot(o))\n",
    "\n",
    "    res2 = np.array(res2)\n",
    "    print(do_intersect(res1, res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os, pickle\n",
    "\n",
    "\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.KMNIST(\"/Users/daniellengyel/deep_generalizability/experiments/KMNIST\", train=True,\n",
    "                                            download=True,\n",
    "                                            transform=torchvision.transforms.Compose([\n",
    "                                                torchvision.transforms.ToTensor(),\n",
    "                                                torchvision.transforms.Normalize(\n",
    "                                                    (0.1307,), (0.3081,))\n",
    "                                            ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array(iter(DataLoader(train_data, batch_size=1, shuffle=True)).next()[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d.reshape(28,28), cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_type = \"best\"\n",
    "\n",
    "if id_type == \"worst\":\n",
    "    exp_id, exp_kendall = min(ce_kendall_coeffs.items(), key=lambda kv: abs(kv[1]))\n",
    "elif id_type == \"best\":\n",
    "    exp_id, exp_kendall = max(ce_kendall_coeffs.items(), key=lambda kv: abs(kv[1]))\n",
    "else:\n",
    "    exp_id, exp_kendall = sorted(ce_kendall_coeffs.items(), key=lambda kv: abs(kv[1]))[len(ce_kendall_coeffs)//2]\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "c1 = [1.        , 0.49803922, 0.05490196, 1.        ]\n",
    "c2 = [0.12156863, 0.46666667, 0.70588235, 1.        ]\n",
    "\n",
    "\n",
    "f, ax1 = plt.subplots(1, figsize=(16,12))\n",
    "\n",
    "x_data = ce_all_point_output_margins[exp_id][\"0\"]\n",
    "y_data = ce_all_point_traces[exp_id][\"0\"]\n",
    "sns.scatterplot(x=x_data, y=y_data, ax=ax1) #, label=\"Kendall Coeff: {:.2f}\".format(exp_kendall))\n",
    "\n",
    "# ax1.tick_params(axis='both', labelbottom=True, labelsize=18)\n",
    "\n",
    "ax1.set_ylabel(ylabel=\"Hessian Trace\", fontsize=22)\n",
    "ax1.set_xlabel(xlabel=\"Output Margin\", fontsize=22)\n",
    "ax1.set_ylim(-250, 3500)\n",
    "\n",
    "\n",
    "ax1.text(x=0.99, y=0.04, transform=ax1.transAxes, s=\"Kendall Coeff: {:.2f}\".format(exp_kendall) ,\\\n",
    "         fontsize=22, verticalalignment='top', horizontalalignment='right',\\\n",
    "        backgroundcolor='white', color=c2)\n",
    "\n",
    "ax1.grid(b=True, which='major')\n",
    "\n",
    "axins2 = inset_axes(ax1, width=4, height=4, loc=1)\n",
    "sns.scatterplot(x=x_data, y=y_data, ax=axins2)\n",
    "\n",
    "# sub region of the original image\n",
    "x1, x2, y1, y2 = 10, 16, -0.6, 1\n",
    "axins2.set_xlim(x1, x2)\n",
    "axins2.set_ylim(y1, y2)\n",
    "\n",
    "# draw a bbox of the region of the inset axes in the parent axes and\n",
    "# connecting lines between the bbox and the inset axes area\n",
    "mark_inset(ax1, axins2, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "\n",
    "#f.legend(loc=\"upper right\", fontsize=20, bbox_to_anchor=(0.4, 0.88))\n",
    "\n",
    "\n",
    "# f.savefig(\"../figs/subset_kendall_{}_{}_{}\".format(id_type, data_name, ce_exp), dpi=300, bbox_inches = \"tight\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(traces, losses)</th>\n",
       "      <th>(traces, jacobian)</th>\n",
       "      <th>(traces, margins)</th>\n",
       "      <th>(losses, traces)</th>\n",
       "      <th>(losses, jacobian)</th>\n",
       "      <th>(losses, margins)</th>\n",
       "      <th>(jacobian, traces)</th>\n",
       "      <th>(jacobian, losses)</th>\n",
       "      <th>(jacobian, margins)</th>\n",
       "      <th>(margins, traces)</th>\n",
       "      <th>...</th>\n",
       "      <th>batch_train_size</th>\n",
       "      <th>criterion</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>seed</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1621787441.2034013</th>\n",
       "      <td>0.678685</td>\n",
       "      <td>0.729476</td>\n",
       "      <td>0.971338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.891396</td>\n",
       "      <td>0.977430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.01</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.5808</td>\n",
       "      <td>0.130931</td>\n",
       "      <td>2.950856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621786700.9018226</th>\n",
       "      <td>0.044733</td>\n",
       "      <td>0.217437</td>\n",
       "      <td>0.043659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437734</td>\n",
       "      <td>0.738720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>MSE</td>\n",
       "      <td>1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.5638</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.068652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621790269.6430342</th>\n",
       "      <td>0.082725</td>\n",
       "      <td>0.028982</td>\n",
       "      <td>0.036462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019699</td>\n",
       "      <td>0.794832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.025</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>0.044973</td>\n",
       "      <td>0.056266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621787496.530556</th>\n",
       "      <td>0.036044</td>\n",
       "      <td>0.145147</td>\n",
       "      <td>0.072186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074712</td>\n",
       "      <td>0.400288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4092</td>\n",
       "      <td>0.4036</td>\n",
       "      <td>1.726392</td>\n",
       "      <td>1.753100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621786647.420346</th>\n",
       "      <td>0.046796</td>\n",
       "      <td>0.093137</td>\n",
       "      <td>0.042303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.201037</td>\n",
       "      <td>0.440233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.187814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>Adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4570</td>\n",
       "      <td>1.584049</td>\n",
       "      <td>1.605596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621786706.9549413</th>\n",
       "      <td>0.060177</td>\n",
       "      <td>0.054584</td>\n",
       "      <td>0.048743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053374</td>\n",
       "      <td>0.783191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.05</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.030660</td>\n",
       "      <td>0.057727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621787550.8746219</th>\n",
       "      <td>0.024064</td>\n",
       "      <td>0.138086</td>\n",
       "      <td>0.047980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114278</td>\n",
       "      <td>0.675255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>1.997544</td>\n",
       "      <td>1.996431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621787382.3898637</th>\n",
       "      <td>0.549985</td>\n",
       "      <td>0.784211</td>\n",
       "      <td>0.908260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696798</td>\n",
       "      <td>0.906974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.075</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.8656</td>\n",
       "      <td>0.5178</td>\n",
       "      <td>0.437320</td>\n",
       "      <td>2.592184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621787594.1609957</th>\n",
       "      <td>0.138199</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>0.072132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122407</td>\n",
       "      <td>0.780054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>cross-entropy</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.2108</td>\n",
       "      <td>2.255276</td>\n",
       "      <td>2.252788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621789512.571569</th>\n",
       "      <td>0.062365</td>\n",
       "      <td>0.038505</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079510</td>\n",
       "      <td>0.764709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.061018</td>\n",
       "      <td>0.065114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    (traces, losses)  (traces, jacobian)  (traces, margins)  \\\n",
       "1621787441.2034013          0.678685            0.729476           0.971338   \n",
       "1621786700.9018226          0.044733            0.217437           0.043659   \n",
       "1621790269.6430342          0.082725            0.028982           0.036462   \n",
       "1621787496.530556           0.036044            0.145147           0.072186   \n",
       "1621786647.420346           0.046796            0.093137           0.042303   \n",
       "...                              ...                 ...                ...   \n",
       "1621786706.9549413          0.060177            0.054584           0.048743   \n",
       "1621787550.8746219          0.024064            0.138086           0.047980   \n",
       "1621787382.3898637          0.549985            0.784211           0.908260   \n",
       "1621787594.1609957          0.138199            0.014171           0.072132   \n",
       "1621789512.571569           0.062365            0.038505           0.027639   \n",
       "\n",
       "                    (losses, traces)  (losses, jacobian)  (losses, margins)  \\\n",
       "1621787441.2034013               NaN            0.891396           0.977430   \n",
       "1621786700.9018226               NaN            0.437734           0.738720   \n",
       "1621790269.6430342               NaN            0.019699           0.794832   \n",
       "1621787496.530556                NaN            0.074712           0.400288   \n",
       "1621786647.420346                NaN            0.201037           0.440233   \n",
       "...                              ...                 ...                ...   \n",
       "1621786706.9549413               NaN            0.053374           0.783191   \n",
       "1621787550.8746219               NaN            0.114278           0.675255   \n",
       "1621787382.3898637               NaN            0.696798           0.906974   \n",
       "1621787594.1609957               NaN            0.122407           0.780054   \n",
       "1621789512.571569                NaN            0.079510           0.764709   \n",
       "\n",
       "                    (jacobian, traces)  (jacobian, losses)  \\\n",
       "1621787441.2034013                 NaN                 NaN   \n",
       "1621786700.9018226                 NaN                 NaN   \n",
       "1621790269.6430342                 NaN                 NaN   \n",
       "1621787496.530556                  NaN                 NaN   \n",
       "1621786647.420346                  NaN                 NaN   \n",
       "...                                ...                 ...   \n",
       "1621786706.9549413                 NaN                 NaN   \n",
       "1621787550.8746219                 NaN                 NaN   \n",
       "1621787382.3898637                 NaN                 NaN   \n",
       "1621787594.1609957                 NaN                 NaN   \n",
       "1621789512.571569                  NaN                 NaN   \n",
       "\n",
       "                    (jacobian, margins)  (margins, traces)  ...  \\\n",
       "1621787441.2034013             0.993934                NaN  ...   \n",
       "1621786700.9018226             0.418955                NaN  ...   \n",
       "1621790269.6430342             0.042675                NaN  ...   \n",
       "1621787496.530556              0.217906                NaN  ...   \n",
       "1621786647.420346              0.187814                NaN  ...   \n",
       "...                                 ...                ...  ...   \n",
       "1621786706.9549413             0.039464                NaN  ...   \n",
       "1621787550.8746219             0.067792                NaN  ...   \n",
       "1621787382.3898637             0.992961                NaN  ...   \n",
       "1621787594.1609957             0.018148                NaN  ...   \n",
       "1621789512.571569              0.064559                NaN  ...   \n",
       "\n",
       "                    batch_train_size      criterion learning_rate optimizer  \\\n",
       "1621787441.2034013               256  cross-entropy          0.01       SGD   \n",
       "1621786700.9018226               256            MSE             1       SGD   \n",
       "1621790269.6430342               128            MSE         0.025       SGD   \n",
       "1621787496.530556                256  cross-entropy      0.000025      Adam   \n",
       "1621786647.420346                256  cross-entropy      0.000025      Adam   \n",
       "...                              ...            ...           ...       ...   \n",
       "1621786706.9549413               128            MSE          0.05       SGD   \n",
       "1621787550.8746219               256  cross-entropy      0.000005      Adam   \n",
       "1621787382.3898637               256  cross-entropy         0.075       SGD   \n",
       "1621787594.1609957               256  cross-entropy      0.000001      Adam   \n",
       "1621789512.571569                128            MSE      0.000075   RMSProp   \n",
       "\n",
       "                   seed weight_decay acc_train acc_test  loss_train  loss_test  \n",
       "1621787441.2034013    0       0.0001    0.9522   0.5808    0.130931   2.950856  \n",
       "1621786700.9018226   10            0    0.9216   0.5638    0.015690   0.068652  \n",
       "1621790269.6430342   10       0.0001    0.7000   0.5888    0.044973   0.056266  \n",
       "1621787496.530556     0       0.0001    0.4092   0.4036    1.726392   1.753100  \n",
       "1621786647.420346     5            0    0.4500   0.4570    1.584049   1.605596  \n",
       "...                 ...          ...       ...      ...         ...        ...  \n",
       "1621786706.9549413   10            0    0.7984   0.6034    0.030660   0.057727  \n",
       "1621787550.8746219    0       0.0001    0.3100   0.3096    1.997544   1.996431  \n",
       "1621787382.3898637    0       0.0001    0.8656   0.5178    0.437320   2.592184  \n",
       "1621787594.1609957    0       0.0001    0.2070   0.2108    2.255276   2.252788  \n",
       "1621789512.571569     5       0.0001    0.5486   0.5030    0.061018   0.065114  \n",
       "\n",
       "[432 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "432it [00:16, 26.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1847, grad_fn=<CopyBackwards>)\n",
      "tensor(0.0803, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "432it [00:15, 27.50it/s]\n"
     ]
    }
   ],
   "source": [
    "root_folder = os.environ[\"PATH_TO_DEEP_FOLDER\"]\n",
    "data_name = \"CIFAR10\"\n",
    "\n",
    "exp_name = \"LeNet_short\"\n",
    "experiment_folder = os.path.join(root_folder, \"experiments\", data_name, exp_name)\n",
    "\n",
    "exp_ids = [\"1621786700.9018226\"]\n",
    "\n",
    "meta = {\"criterion\": \"cross-entropy\", \"normalize_output\": False}\n",
    "traces_CE = mf_post.postprocess_experiment.compute_on_experiment(experiment_folder, \"point_traces\", exp_ids, -1, 0, 100, on_test_set=False, device=None, verbose=True, check_cache=False, meta=meta)\n",
    "\n",
    "meta = {\"criterion\": \"cross-entropy\", \"normalize_output\": True}\n",
    "traces_new_norm_CE = mf_post.postprocess_experiment.compute_on_experiment(experiment_folder, \"point_traces\", exp_ids, -1, 0, 100, on_test_set=False, device=None, verbose=True, check_cache=False, meta=meta)\n",
    "\n",
    "# meta = {\"criterion\": \"MSE\"}\n",
    "# traces_MSE = mf_post.postprocess_experiment.compute_on_experiment(experiment_folder, \"point_traces\", exp_ids, -1, 0, 100, on_test_set=False, device=None, verbose=True, check_cache=False, meta=meta)\n",
    "\n",
    "# meta = {\"criterion\": \"normalized-cross-entropy\"}\n",
    "# traces_norm_CE = mf_post.postprocess_experiment.compute_on_experiment(experiment_folder, \"point_traces\", exp_ids, -1, 0, 100, on_test_set=False, device=None, verbose=True, check_cache=False, meta=meta)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "432it [00:00, 1733.32it/s]\n"
     ]
    }
   ],
   "source": [
    "meta = None # {\"criterion\": \"cross-entropy\"}\n",
    "jacob = mf_post.postprocess_experiment.compute_on_experiment(experiment_folder, \"inp_out_jacobian\", exp_ids, -1, 0, 100, on_test_set=False, device=None, verbose=True, check_cache=False, meta=meta)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins = mf_post.postprocess_experiment.compute_on_experiment(experiment_folder, \"output_margins\", exp_ids, -1, 0, 100, on_test_set=False, device=None, verbose=True, check_cache=False, meta=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jacob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6f61531113ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraces_new_norm_CE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plt.xlim(-10, 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jacob' is not defined"
     ]
    }
   ],
   "source": [
    "exp_id = exp_ids[0]\n",
    "x_data = traces_new_norm_CE[exp_id]['0']\n",
    "y_data = jacob[exp_id]['0']\n",
    "plt.scatter(x_data, y_data)\n",
    "# plt.xlim(-10, 20)\n",
    "# plt.ylim(-0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'post_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0ebc69966b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpost_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexp_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1621270447.8047616\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"losses\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"jacobian\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'post_dict' is not defined"
     ]
    }
   ],
   "source": [
    "post_dict\n",
    "exp_id = \"1621270447.8047616\"\n",
    "x_data = post_dict[\"losses\"][exp_id]['0']\n",
    "y_data = post_dict[\"jacobian\"][exp_id]['0']\n",
    "plt.scatter(x_data, y_data)\n",
    "# plt.xlim(-10, 20)\n",
    "# plt.ylim(-0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=0.8611560402224373, pvalue=6.717015901950283e-37)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_post.correlation.get_kendall(x_data, y_data, remove_outliers=False)#, increasing=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = mf_post.postprocess_experiment.get_exp_loss_acc(experiment_folder, -1, seed=0, num_train_datapoints=1000, num_test_datapoints=200, device=None, check_cache = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(data=[loss[k]['0'] for k in loss], index=list(loss.keys()), columns=[\"train_loss\", \"test_loss\"])\n",
    "acc_df = pd.DataFrame(data=[acc[k]['0'] for k in acc], index=list(acc.keys()), columns=[\"train_acc\", \"test_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "May19_00-32-38_cx3-7-9.cx3.hpc.ic.ac.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = os.environ[\"PATH_TO_DEEP_FOLDER\"]\n",
    "data_name = \"KMNIST\"\n",
    "\n",
    "exp_name = \"\"\n",
    "\n",
    "exp_name = \"w128_l8_ReLU\" # \"May19_00-32-38_cx3-7-9.cx3.hpc.ic.ac.uk\" # \"May19_02-49-40_cx3-3-0.cx3.hpc.ic.ac.uk\"#\n",
    "experiment_folder = os.path.join(root_folder, \"experiments\", data_name, exp_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_gen",
   "language": "python",
   "name": "deep_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
